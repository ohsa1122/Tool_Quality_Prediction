{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "Wd0NFwMESSLm"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "from scipy import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "Rkl-o88EeaXT"
      },
      "outputs": [],
      "source": [
        "root_dir_zero = \"/content/zero/0\"\n",
        "zero = listdir(root_dir_zero)\n",
        "\n",
        "root_dir_one = \"/content/one/1\"\n",
        "one = listdir(root_dir_one)\n",
        "\n",
        "root_dir_two = \"/content/two/2\"\n",
        "two = listdir(root_dir_two)\n",
        "\n",
        "root_dir_three = \"/content/three/3\"\n",
        "three = listdir(root_dir_three)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "rQzWxvS4Scla"
      },
      "outputs": [],
      "source": [
        "def data_to_dict(file_name, root_dir, condition):\n",
        "    dataframes = []\n",
        "    for sub_dir in file_name:\n",
        "        if 'readme' not in sub_dir:\n",
        "            mat = io.loadmat(join(root_dir, sub_dir))\n",
        "            features = ['AE', 'disp', 'power', 'sound']\n",
        "            feat_dict = {}\n",
        "            for i, feat in enumerate(features):\n",
        "                feat_dict[feat] = mat[\"processed\"][0][0][i].flatten()\n",
        "            dataframes.append(pd.DataFrame(feat_dict, index=np.arange(len(mat[\"processed\"][0][0][0]))))\n",
        "    return dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "qIEp_rohXZGs"
      },
      "outputs": [],
      "source": [
        "all_files = []\n",
        "zero_dict = data_to_dict(zero, root_dir_zero, 0)\n",
        "one_dict = data_to_dict(one, root_dir_one, 1)\n",
        "two_dict = data_to_dict(two, root_dir_two, 2)\n",
        "three_dict = data_to_dict(three, root_dir_three, 3)\n",
        "all_files.append(zero_dict)\n",
        "all_files.append(one_dict)\n",
        "all_files.append(two_dict)\n",
        "all_files.append(three_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "fn1IK1jNZjsa"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "-ddUYCalNGlu"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for i, f in enumerate(all_files):\n",
        "    for df in f:\n",
        "        #if len(df) == 100001:    \n",
        "        df = df.iloc[::100, :]\n",
        "        df = df.iloc[:1000, :]\n",
        "        data.append([df, i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "LKh19tr7NToa"
      },
      "outputs": [],
      "source": [
        "class TSdata(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        self.data = data\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        df = self.data[index][0]\n",
        "        self.x = torch.tensor(df[[\"AE\", \"disp\", \"power\", \"sound\"]].values,dtype = torch.double)\n",
        "        self.y = torch.tensor(self.data[index][1], dtype = torch.long)\n",
        "        return [self.x,self.y]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "tMaEkDNRNVRx"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "input_size = 4\n",
        "seq_len = 1000\n",
        "num_layers = 4\n",
        "hidden_size = 32\n",
        "num_classes = 4\n",
        "learning_rate = 2e-3\n",
        "num_epochs = 100\n",
        "dataset = TSdata(data)\n",
        "loader = DataLoader(dataset, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un2qFBNANZnH",
        "outputId": "16170a21-c4b4-4282-a7e3-c341b0689402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Train: 170\n",
            "Num Test: 30\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data = random_split(dataset, [170,30])\n",
        "    \n",
        "\n",
        "print(f'Num Train: {len(train_data)}')\n",
        "print(f'Num Test: {len(test_data)}')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "MY58vSPuNbcc"
      },
      "outputs": [],
      "source": [
        "class _RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, device):\n",
        "        super(_RNN,self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True).to(device)\n",
        "        #x -> (batch_size, seq_len, input_size)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes).to(device)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        \n",
        "        x = x.double()\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device).double()\n",
        "        \n",
        "        out, _ = self.rnn(x, h0)\n",
        "        \n",
        "        #out ->  (batch_size, seq_len, hidden_size)\n",
        "        \n",
        "        out = out[: , -1, :]\n",
        "        \n",
        "        # out -> (batch_size, hidden_size)\n",
        "        \n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Z8o46hl7epYG"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "2CHH7SoKNdw1"
      },
      "outputs": [],
      "source": [
        "model = _RNN(input_size, hidden_size, num_layers, num_classes, device=device).double()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yUN-Vh8zNiFM",
        "outputId": "7ea7a1d1-023f-4730-89ff-a4da921074df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1 / 100], Step [3/ 17], Loss: 1.3536930875177968, Val Loss: 1.4441991783597536\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.4823017318604443, Val Loss: 1.502930738567915\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.5059620879424822, Val Loss: 1.5302279790178448\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.4180838848516, Val Loss: 1.406773568291877\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.3921533918384514, Val Loss: 1.4309984922524304\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.3520453843094242, Val Loss: 1.43048505603419\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.4066829244830144, Val Loss: 1.440667702926477\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.4197520802964712, Val Loss: 1.4162296056700674\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.376600007091323, Val Loss: 1.4173240630237616\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.369653643098577, Val Loss: 1.4100882521671891\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.383489906068543, Val Loss: 1.4339631382437865\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.3868071497081471, Val Loss: 1.4443252977865193\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.377632207702808, Val Loss: 1.4145369730989275\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.37480677867403, Val Loss: 1.4317621393448163\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.440219528237923, Val Loss: 1.4276320781374456\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.3783090534534588, Val Loss: 1.4862109927187106\n",
            "epoch [1 / 100], Step [3/ 17], Loss: 1.343966595873604, Val Loss: 1.462367842512388\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.6417091634938618, Val Loss: 2.182146879500151\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 1.0783011374731692, Val Loss: 2.3406680094580214\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.9927376483256628, Val Loss: 2.3826004201395574\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.7721238579624663, Val Loss: 1.958161238816134\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.9099470503181604, Val Loss: 2.149567088144623\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.6798068132780537, Val Loss: 2.0685666038359427\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.7871174582466424, Val Loss: 2.0526763420651886\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 1.1581015355757727, Val Loss: 1.8214147588021465\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.7380306317207728, Val Loss: 1.8497770849438595\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.7907794059690889, Val Loss: 2.206360446917193\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.8338038807162599, Val Loss: 2.084255474339103\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.9312681815662376, Val Loss: 1.6538968728197514\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 1.0028135526895035, Val Loss: 1.7962469460114938\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.9922280941762749, Val Loss: 1.9435656153479588\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.8065343262042756, Val Loss: 1.885736631152703\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 1.003138080141074, Val Loss: 1.8429050797856508\n",
            "epoch [21 / 100], Step [3/ 17], Loss: 0.8835001805628266, Val Loss: 1.7755840997902497\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.05092616758446357, Val Loss: 3.1694564673808454\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.03895086664047297, Val Loss: 3.5126456142985747\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.04629241500718762, Val Loss: 3.255566240865343\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.09399115413571454, Val Loss: 2.128774555040592\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.015555882418157543, Val Loss: 2.8646855181628923\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.04926766318560795, Val Loss: 2.1860240114830853\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.038801015338007096, Val Loss: 3.6769498670911567\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.033805469465317615, Val Loss: 3.316724942464269\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.042191381411179646, Val Loss: 2.9534579837020485\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.03993833193794559, Val Loss: 2.3844562697574903\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.05115042715709843, Val Loss: 2.9155454627854342\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.03680337116024224, Val Loss: 2.3874742300147385\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.03820346967240078, Val Loss: 3.68844699576006\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.04058010582403694, Val Loss: 3.0487490906852264\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.11395550093777118, Val Loss: 2.9303310275574894\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.034519974382946864, Val Loss: 2.5807219130115113\n",
            "epoch [41 / 100], Step [3/ 17], Loss: 0.03619654020491256, Val Loss: 3.8048485556554743\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-173-dfce2be5f52c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msignals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-170-484840a31713>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#out ->  (batch_size, seq_len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    471\u001b[0m                 result = _VF.rnn_tanh(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m    472\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                                       self.batch_first)\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 result = _VF.rnn_relu(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Training the RNN: \n",
        "\n",
        "total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (signals, label) in enumerate(train_loader):\n",
        "                # forward pass\n",
        "        signals, label = signals.to(device), label.to(device)\n",
        "        outputs = model(signals)\n",
        "        loss = criterion(outputs, label)\n",
        "        \n",
        "        #backward and optimization \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        model.eval()\n",
        "        for i, (signals_test, label_test) in enumerate(test_loader):\n",
        "            signals_test, label_test = signals_test.to(device), label_test.to(device)\n",
        "            output_test = model(signals_test)\n",
        "            val_loss = criterion(output_test, label_test)\n",
        "        model.train()\n",
        "        print(f'epoch [{epoch + 1} / {num_epochs}], Step [{i+1}/ {total_steps}], Loss: {loss.item()}, Val Loss: {val_loss.item()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HgSSG-4-iapJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "osama2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
